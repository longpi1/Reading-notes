# 00.OpenAI API的主要接口与参数详解

> 详细接口和参数可以查看一下 [官方文档](https://platform.openai.com/docs/api-reference/completions/create)。

## 主要参数

1. **`model`（模型）**：

   - **描述**：指定要使用的模型。在GPT-3的情况下，该值为"gpt-3.5-turbo"。
   - **示例**：`"model": "gpt-3.5-turbo"`

2. **`prompt`（提示）**：

   - **描述**：提供给模型的输入文本或提示。这是您希望模型生成响应的关键信息。
   - **示例**：`"prompt": "Translate the following English text to French: '{}'"`

3. **`max_tokens`（最大标记数）**：

   - **描述**：限制生成文本的最大标记数。这可以用于控制生成文本的长度，你可以简单地把token理解成一个单词。实际上，token是分词之后的一个字符序列里的一个单元。有时候，一个单词会被分解成两个token。比如，icecream是一个单词，但是实际在大语言模型里，会被拆分成 ice 和 cream 两个token。这样分解可以帮助模型更好地捕捉到单词的含义和语法结构。一般来说，750个英语单词就需要1000个token。我们这里用的 text-davinci-003 模型，允许最多有4096个token。需要注意，这个数量既包括你输入的提示语，也包括AI产出的回答，两个加起来不能超过4096个token。比如，你的输入有1000个token，那么你这里设置的 max\_tokens 就不能超过 3096。不然调用就会报错。
   - **示例**：`"max_tokens": 50`

4. **`temperature`（温度）**：

   - **描述**：控制生成文本的创造性程度。较高的温度值会导致更随机和创造性的输出，而较低的值则会导致更确定和保守的输出（*temperature* 越大，则新的概率分布越均匀，随机性也就越大，越容易生成一些意想不到的词）。这个参数的输入范围是0-2之间的浮点数，代表输出结果的随机性或者说多样性。。
   - **示例**：`"temperature": 0.8`

5. **`stop`（停止词）**：

   - **描述**：一个字符串或字符串列表，用于指定在生成文本中的何处停止。
   - **示例**：`"stop": ["###", "\n"]`

6. **`n`（数量）**：

   - **描述**：用于指定生成多少个不同的文本响应。这是一个可选参数。
   - **示例**：`"n": 5`

7. **`stream`（流式传输）**：

   - **描述**：如果将其设置为`True`，则 API 将立即返回响应 ID，而不会等到生成的文本准备好后再返回。
   - **示例**：`"stream": True`

8. **`log_level`（日志级别）**：

   - **描述**：用于指定日志记录的详细程度。可选值为`"info"`、`"warning"`或`"error"`。
   - **示例**：`"log_level": "info"`

9. **对数 logprobs**：
   包括最可能的令牌的日志概率，以及所选令牌。例如，如果为 5，则 API 将返回 5 个最可能的令牌的列表。API 将始终返回采样令牌的 ，因此响应中最多可能有元素。

10. **回显 echo**：

    除了完成之外，还回显提示

11. **top_p （number，选填，Defaults to 1）**

    一种替代温度采样的方法叫做核心采样，模型会考虑到具有 top_p 概率质量的标记结果。因此，0.1 表示只有占前 10% 概率质量的标记被考虑。

    我们通常建议修改这个（top_p ）或者 temperature，但不要同时修改两者。



## 主要接口

### 1.1. [Models](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Fmodels) 模型

列出并描述 API 中可用的各种模型。您可以参考 [模型文档](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fmodels) 以了解可用的模型以及它们之间的差异。

####  [List models](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Fmodels%2Flist) 列出模型

```json
GET
https://api.openai.com/v1/models
```

列出当前可用的模型，并提供有关每个模型的基本信息，例如所有者和可用性。

请求演示：

```json
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

响应：

```json
{
  "data": [
    {
      "id": "model-id-0",
      "object": "model",
      "owned_by": "organization-owner",
      "permission": [...]
    },
    {
      "id": "model-id-1",
      "object": "model",
      "owned_by": "organization-owner",
      "permission": [...]
    },
    {
      "id": "model-id-2",
      "object": "model",
      "owned_by": "openai",
      "permission": [...]
    },
  ],
  "object": "list"
}
```

### [Retrieve model](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Fmodels%2Fretrieve) 检索模型

```json
GET 
https://api.openai.com/v1/models/{model}
```

检索模型实例，提供有关模型的基本信息，例如所有者和权限。

其中，`model` 为必填的字符串类型，用于此请求的模型的 ID。

请求演示：

```json
curl https://api.openai.com/v1/models/text-davinci-003 \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

响应：

```json
{
  "id": "text-davinci-003",
  "object": "model",
  "owned_by": "openai",
  "permission": [...]
}
```

### 1.2. [Completions](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Fcompletions)

给定一个提示，模型将返回一个或多个预测的完成，并且还可以在每个位置返回替代令牌的概率。

#### [Create completion](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Fcompletions%2Fcreate)

```json
POST 
https://api.openai.com/v1/completions
```

为提供的提示和参数创建完成。

请求演示：

```json
curl https://api.openai.com/v1/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "text-davinci-003",
    "prompt": "Say this is a test",
    "max_tokens": 7,
    "temperature": 0
  }'
```

响应：

```json
{
  "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
  "object": "text_completion",
  "created": 1589478378,
  "model": "text-davinci-003",
  "choices": [
    {
      "text": "\n\nThis is indeed a test",
      "index": 0,
      "logprobs": null,
      "finish_reason": "length"
    }
  ],
  "usage": {
    "prompt_tokens": 5,
    "completion_tokens": 7,
    "total_tokens": 12
  }
}
```

#### Request body(入参详解)

> - **`model` （string，必填）**
>
> 要使用的模型的 ID。可以使用 [列表模型API ](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Fmodels%2Flist) (GET [api.openai.com/v1/models](https://link.juejin.cn?target=https%3A%2F%2Fapi.openai.com%2Fv1%2Fmodels)) 查看所有可用模型，或参阅 [模型概述](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fmodels%2Foverview) 了解它们的描述。
>
> - **`prompt` （string or array，选填，Defaults to <|endoftext|>）**
>
> 用于生成完成、编码为字符串、字符串数组、标记数组或标记数组数组的提示。
>
> 注意 |endoftext| 是模型在训练期间看到的文档分隔符，因此如果未指定提示，模型将生成，就像从新文档的开头一样。
>
> - **`suffix` （string，选填，Defaults to null）**
>
> 完成插入文本后的后缀。
>
> - **`max_tokens` （integer，选填，Defaults to 16）**
>
> 完成时要生成的最大 [token](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Ftokenizer) 数。
>
> 提示 `max_tokens` 的 token 计数不能超过模型的上下文长度。大多数模型的上下文长度为 2048 个令牌（最新模型除外，它支持 4096）
>
> - **`temperature` （number，选填，Defaults to 1）**
>
> 使用哪个采样温度，在 **0和2之间**。
>
> 较高的值，如0.8会使输出更随机，而较低的值，如0.2会使其更加集中和确定性。
>
> 我们通常建议修改这个（`temperature` ）为 `top_p` 但两者不能同时存在，二选一。
>
> - **`top_p` （number，选填，Defaults to 1）**
>
> 一种替代温度采样的方法叫做核心采样，模型会考虑到具有 top_p 概率质量的标记结果。因此，0.1 表示只有占前 10% 概率质量的标记被考虑。
>
> 我们通常建议修改这个（`top_p` ）或者 `temperature`，但不要同时修改两者。
>
> - **`n` （integer，选填，Defaults to 1）**
>
> 每个 `prompt` 生成的完成次数。
>
> 注意：由于此参数会生成许多完成，因此它会快速消耗您的令牌配额。小心使用，并确保对 `max_tokens` 和 `stop` 进行合理的设置。
>
> - **`stream` （boolean，选填，Defaults to false）**
>
> 是否返回部分进度流。如果设置，令牌将作为数据服务器推送事件随着它们变得可用而发送，流通过 `data: [DONE]` 消息终止。
>
> - **`logprobs` （integer，选填，Defaults to null）**
>
> 在 `logprobs` 返回的最有可能的标记列表中，包括所选标记和对应的对数概率。
>
> 例如，如果 `logprobs` 为 5，则 API 将返回一个由 5 个最有可能的标记组成的列表。API 总是会返回采样标记的对数概率，因此响应中可能会有多达 `logprobs+1` 个元素。
>
> `logprobs` 的最大值为 5。
>
> - **`echo` （boolean，选填，Defaults to false）**
>
> 除了完成之外，还回显提示
>
> - **`stop` （string or array，选填，Defaults to null）**
>
> 最多生成4个序列，API将停止生成更多的标记。返回的文本不包含停止序列。
>
> - **`presence_penalty` （number，选填，Defaults to 0）**
>
> 介于 **-2.0 和 2.0 之间**的数字。正值会根据它们是否出现在文本中迄今为止来惩罚新令牌，从而增加模型谈论新主题的可能性。
>
> [请参阅有关频率和状态惩罚的更多信息](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Fparameter-details)
>
> - **`frequency_penalty` （number，选填，Defaults to 0）**
>
> 介于-2.0和2.0之间的数字。正值会根据文本中新令牌的现有频率对其进行惩罚，从而降低模型重复相同行的可能性。
>
> [请参阅有关频率和存在惩罚的更多信息](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Fparameter-details)
>
> - **`best_of` （integer，选填，Defaults to 1）**
>
> 在生成服务器端生成 `best_of` 完成，并返回“最佳”（每个标记具有最高对数概率的那一个）。结果无法流式传输。
>
> 当与 `n` 一起使用时，`best_of` 控制候选完成的数量，`n` 指定要返回多少个 - `best_of` 必须大于 `n`。
>
> 注意：由于此参数生成许多完成，因此可能会快速消耗您的令牌配额。请小心使用并确保 `max_tokens` 和 `stop` 设置合理。
>
> - **`logit_bias` （map，选填，Defaults to null）**
>
> 修改指定标记在完成中出现的可能性。
>
> 接受一个JSON对象，将标记（由GPT分词器中的标记ID指定）映射到从 -100 到 100 的相关偏差值。您可以使用此 [分词器工具](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Ftokenizer%3Fview%3Dbpe)（适用于GPT-2和GPT-3）将文本转换为令牌ID。数学上，在采样之前，模型生成的 logits 会添加偏差。确切的效果因模型而异，但是介于-1和1之间的值应该会减少或增加选择的可能性；像 -100 或 100 这样的值应该会导致相关令牌被禁止或独占选择。
>
> 例如，您可以传递 `{"50256": -100}` 来防止生成
>
> - **`user` （string，选填）**
>
> 一个唯一的标识符，代表您的终端用户，可以帮助OpenAI监测和检测滥用。[了解更多信息](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fguides%2Fsafety-best-practices%2Fend-user-ids)。

### 1.3. [Chat](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Fchat) 聊天

给定一组描述对话的消息列表，模型将返回一个回复。

#### [Create chat completion](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Fchat%2Fcreate)

```json
POST
https://api.openai.com/v1/chat/completions
```

为给定的聊天对话创建模型响应。

请求演示：

```json
curl https://api.openai.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-3.5-turbo",
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
```

响应：

```json
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "created": 1677652288,
  "choices": [{
    "index": 0,
    "message": {
      "role": "assistant",
      "content": "\n\nHello there, how may I assist you today?",
    },
    "finish_reason": "stop"
  }],
  "usage": {
    "prompt_tokens": 9,
    "completion_tokens": 12,
    "total_tokens": 21
  }
}
```

#### Request body(入参详解)

> - **`model` （string，必填）**
>
>   要使用的模型ID。有关哪些模型适用于Chat API的详细信息，请查看 [模型端点兼容性表](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fmodels%2Fmodel-endpoint-compatibility)
>
> - **`messages` （array，必填）**
>
>   迄今为止描述对话的消息列表
>
>   - **`role` （string，必填）**
>
>     此消息的作者角色。`system` 、`user` 或 `assistant` 之一
>
>   - **`content` （string，必填）**
>
>     消息的内容
>
>   - **`name` （string，选填）**
>
>     此消息的作者的姓名。可以包含 a-z、A-Z、0-9 和下划线，最大长度为 64 个字符
>
> - **`temperature` （number，选填，Defaults to 1）**
>
>   使用哪个采样温度，在 **0和2之间**。
>
>   较高的值，如0.8会使输出更随机，而较低的值，如0.2会使其更加集中和确定性。
>
>   我们通常建议修改这个（`temperature` ）为 `top_p` 但两者不能同时存在，二选一。
>
> - **`top_p` （number，选填，Defaults to 1）**
>
>   一种替代温度采样的方法叫做核心采样，模型会考虑到具有 top_p 概率质量的标记结果。因此，0.1 表示只有占前 10% 概率质量的标记被考虑。
>
>   我们通常建议修改这个（`top_p` ）或者 `temperature`，但不要同时修改两者。
>
> - **`n` （integer，选填，Defaults to 1）**
>
>   每个输入消息要生成多少聊天完成选项数
>
> - **`stream` （boolean，选填，Defaults to false）**
>
>   如果设置了，将发送部分消息增量，就像在 ChatGPT 中一样。令牌将作为数据 [服务器推送事件](https://link.juejin.cn?target=https%3A%2F%2Fdeveloper.mozilla.org%2Fen-US%2Fdocs%2FWeb%2FAPI%2FServer-sent_events%2FUsing_server-sent_events%23event_stream_format) 随着它们变得可用而被发送，流通过 `data: [DONE]` 消息终止。请参阅OpenAI Cookbook 以获取 [示例代码](https://link.juejin.cn?target=https%3A%2F%2Fgithub.com%2Fopenai%2Fopenai-cookbook%2Fblob%2Fmain%2Fexamples%2FHow_to_stream_completions.ipynb)。
>
> - **stop （string or array，选填，Defaults to null）**
>
>   最多生成4个序列，API将停止生成更多的标记。
>
> - **`max_tokens` （integer，选填，Defaults to inf）**
>
>   在聊天完成中生成的最大 [tokens](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Ftokenizer) 数。
>
>   输入令牌和生成的令牌的总长度受模型上下文长度的限制。
>
> - **`presence_penalty` （number，选填，Defaults to 0）**
>
>   介于 **-2.0 和 2.0 之间**的数字。正值会根据它们是否出现在文本中迄今为止来惩罚新令牌，从而增加模型谈论新主题的可能性。
>
>   [请参阅有关频率和状态惩罚的更多信息](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Fparameter-details)
>
> - **`frequency_penalty` （number，选填，Defaults to 0）**
>
>   介于-2.0和2.0之间的数字。正值会根据文本中新令牌的现有频率对其进行惩罚，从而降低模型重复相同行的可能性。
>
>   [请参阅有关频率和存在惩罚的更多信息](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Fparameter-details)
>
> - **`logit_bias` （map，选填，Defaults to null）**
>
>   修改完成时指定标记出现的可能性。
>
>   接受一个JSON对象，将标记（由分词器中的标记ID指定）映射到从 -100 到 100 的相关偏差值。在采样之前，模型生成的logits会加上这个偏差。确切的影响因模型而异，但是 -1 到 1 之间的值应该会减少或增加选择概率；像 -100 或 100 这样的值应该会导致相关标记被禁止或独占选择。
>
> - **`user` （string，选填）**
>
>   一个唯一的标识符，代表您的终端用户，可以帮助OpenAI监测和检测滥用。[了解更多信息](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fguides%2Fsafety-best-practices%2Fend-user-ids)。

### 1.4 [Edits](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Fedits) 

给定一个提示和一条指令，模型将返回提示的编辑版本。

#### [Create edit](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Fedits%2Fcreate)

```json
POST
https://api.openai.com/v1/edits
```

为提供的输入、指令和参数创建一个新的编辑。

请求演示：

```json
curl https://api.openai.com/v1/edits \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "text-davinci-edit-001",
    "input": "What day of the wek is it?",
    "instruction": "Fix the spelling mistakes"
  }'
```

响应：

```json
{
  "object": "edit",
  "created": 1589478378,
  "choices": [
    {
      "text": "What day of the week is it?",
      "index": 0,
    }
  ],
  "usage": {
    "prompt_tokens": 25,
    "completion_tokens": 32,
    "total_tokens": 57
  }
}
```

#### Request body(入参详解)

> - **`model` （string，必填）**
>
>   要使用的模型ID。您可以在此端点中使用 `text-davinci-edit-001` 或 `code-davinci-edit-001` 模型。
>
> - **`input` （string，选填，Defaults to ''）**
>
>   用作编辑起点的输入文本。
>
> - **`instruction` （string，必填）**
>
>   指导模型如何编辑提示的说明。
>
> - **`n` （integer，选填，Defaults to 1）**
>
>   输入和指令需要生成多少次编辑。
>
> - **`temperature` （number，选填，Defaults to 1）**
>
>   使用哪个采样温度，在 **0和2之间**。
>
>   较高的值，如0.8会使输出更随机，而较低的值，如0.2会使其更加集中和确定性。
>
>   我们通常建议修改这个（`temperature` ）为 `top_p` 但两者不能同时存在，二选一。
>
> - **`top_p` （number，选填，Defaults to 1）**
>
>   一种替代温度采样的方法叫做核心采样，模型会考虑到具有 top_p 概率质量的标记结果。因此，0.1 表示只有占前 10% 概率质量的标记被考虑。
>
>   我们通常建议修改这个（`top_p` ）或者 `temperature`，但不要同时修改两者。

### 1.5. [Images](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Fimages) 图像

给定一个提示和/或输入图像，模型将生成一张新的图像。

相关指南：[图像生成](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fguides%2Fimages)。

####  [Create image](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Fimages%2Fcreate)

```json
POST
https://api.openai.com/v1/images/generations
```

根据提示创建图像。

请求演示：

```json
curl https://api.openai.com/v1/images/generations \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "prompt": "A cute baby sea otter",
    "n": 2,
    "size": "1024x1024"
  }'
```

响应：

```json
{
  "created": 1589478378,
  "data": [
    {
      "url": "https://..."
    },
    {
      "url": "https://..."
    }
  ]
}
```

#### Request body(入参详解)

> - **`prompt` （string，必填）**
>
>   所需图像的文本描述。最大长度为1000个字符。
>
> - **`n` （integer，选填，Defaults to 1）**
>
>   要生成的图像数量。必须在1到10之间。
>
> - **`size` （string，选填，Defaults to 1024x1024）**
>
>   生成图像的尺寸。必须是 `256x256` 、`512x512` 或 `1024x1024` 之一。
>
> - **`response_format` （string，选填，Defaults to url）**
>
>   生成的图像返回格式。必须是 `url` 或 `b64_json` 之一。
>
> - **`user` （string，选填）**
>
>   一个唯一的标识符，代表您的终端用户，可以帮助OpenAI监测和检测滥用。[了解更多信息](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fguides%2Fsafety-best-practices%2Fend-user-ids)。

####  [Create image edit](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Fimages%2Fcreate-edit)

```json
POST
https://api.openai.com/v1/images/edits
```

根据原始图像和提示创建编辑或扩展的图像。

请求演示：

```json
curl https://api.openai.com/v1/images/edits \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F image="@otter.png" \
  -F mask="@mask.png" \
  -F prompt="A cute baby sea otter wearing a beret" \
  -F n=2 \
  -F size="1024x1024"
```

响应：

```json
{
  "created": 1589478378,
  "data": [
    {
      "url": "https://..."
    },
    {
      "url": "https://..."
    }
  ]
}
```

#### Request body(入参详解)

> - **`image` （string，必填）**
>
>   要编辑的图像。必须是有效的PNG文件，小于4MB且为正方形。如果未提供遮罩，则图像必须具有透明度，该透明度将用作遮罩。
>
> - **`mask` （string，选填）**
>
>   一个额外的图像，其完全透明的区域（例如 alpha 值为零的区域）指示应该编辑图像的位置。`image` 必须是有效的 PNG 文件，小于 4MB，并且具有与 `image` 相同的尺寸。
>
> - **`prompt` （string，必填）**
>
>   所需图像的文本描述。最大长度为1000个字符。
>
> - **`n` （integer，选填，Defaults to 1）**
>
>   要生成的图像数量。必须在1到10之间。
>
> - **`size` （string，选填，Defaults to 1024x1024）**
>
>   生成图像的尺寸。必须是 `256x256` 、`512x512` 或 `1024x1024` 之一。
>
> - **`response_format` （string，选填，Defaults to url）**
>
>   生成的图像返回格式。必须是 `url` 或 `b64_json` 之一。
>
> - **`user` （string，选填）**
>
>   一个唯一的标识符，代表您的终端用户，可以帮助OpenAI监测和检测滥用。[了解更多信息](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fguides%2Fsafety-best-practices%2Fend-user-ids)。

####  [Create image variation](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Fimages%2Fcreate-variation)

```json
POST
https://api.openai.com/v1/images/variations
```

创建给定图像的变体。

请求演示：

```json
curl https://api.openai.com/v1/images/variations \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F image="@otter.png" \
  -F n=2 \
  -F size="1024x1024"
```

响应：

```json
{
  "created": 1589478378,
  "data": [
    {
      "url": "https://..."
    },
    {
      "url": "https://..."
    }
  ]
}
```

#### Request body(入参详解)

> - **`image` （string，必填）**
>
>   用作变体基础的图像。必须是有效的PNG文件，小于4MB，并且为正方形。
>
> - **`n` （integer，选填，Defaults to 1）**
>
>   要生成的图像数量。必须在1到10之间。
>
> - **`size` （string，选填，Defaults to 1024x1024）**
>
>   生成图像的尺寸。必须是 `256x256` 、`512x512` 或 `1024x1024` 之一。
>
> - **`response_format` （string，选填，Defaults to url）**
>
>   生成的图像返回格式。必须是 `url` 或 `b64_json` 之一。
>
> - **`user` （string，选填）**
>
>   一个唯一的标识符，代表您的终端用户，可以帮助OpenAI监测和检测滥用。[了解更多信息](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fguides%2Fsafety-best-practices%2Fend-user-ids)。

### 1.6. [Embeddings](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Fembeddings) 嵌入

获得一个给定输入的向量表示，可以轻松地被机器学习模型和算法使用。

相关指南：[嵌入](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fguides%2Fembeddings)

#### 1. **[Create embeddings](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Fembeddings%2Fcreate)**

```json
POST
https://api.openai.com/v1/embeddings
```

创建一个嵌入向量，代表输入的文本。

请求演示：

```json
curl https://api.openai.com/v1/embeddings \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "input": "The food was delicious and the waiter...",
    "model": "text-embedding-ada-002"
  }'
```

响应：

```json
{
  "object": "list",
  "data": [
    {
      "object": "embedding",
      "embedding": [
        0.0023064255,
        -0.009327292,
        .... (1536 floats total for ada-002)
        -0.0028842222,
      ],
      "index": 0
    }
  ],
  "model": "text-embedding-ada-002",
  "usage": {
    "prompt_tokens": 8,
    "total_tokens": 8
  }
}
```

#### Request body(入参详解)

> - **`model` （string，必填）**
>
>   要使用的 **模型ID**。您可以使用 [列出模型](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Fmodels%2Flist) API查看所有可用模型，或者请参阅我们的 [模型概述](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fmodels%2Foverview) 以了解它们的描述。
>
> - **`input` （string or array，必填）**
>
>   输入文本以获取嵌入，编码为字符串或令牌数组。要在单个请求中获取多个输入的嵌入，请传递字符串数组或令牌数组的数组。每个输入长度**不得超过 8192 个标记**。
>
> - **`user` （string，选填）**
>
>   一个唯一的标识符，代表您的终端用户，可以帮助OpenAI监测和检测滥用。[了解更多信息](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fguides%2Fsafety-best-practices%2Fend-user-ids)。

### 1.7. [Files](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Ffiles) 文件

**Files** 用于上传文档，可与 [Fine-tuning](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Ffine-tunes) 等功能一起使用。

####  [List files](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Ffiles%2Flist)

```json
GET
https://api.openai.com/v1/files
```

返回属于用户组织的文件列表。

请求演示：

```json
curl https://api.openai.com/v1/files \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

响应：

```json
json复制代码{
  "data": [
    {
      "id": "file-ccdDZrC3iZVNiQVeEA6Z66wf",
      "object": "file",
      "bytes": 175,
      "created_at": 1613677385,
      "filename": "train.jsonl",
      "purpose": "search"
    },
    {
      "id": "file-XjGxS3KTG0uNmNOK362iJua3",
      "object": "file",
      "bytes": 140,
      "created_at": 1613779121,
      "filename": "puppy.jsonl",
      "purpose": "search"
    }
  ],
  "object": "list"
}
```

#### [Upload file](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Ffiles%2Fupload)

```json
POST
https://api.openai.com/v1/files
```

上传包含文档的文件以在各个端点/功能之间使用。目前，一个组织上传的所有文件的大小可以高达1 GB。如果您需要增加存储限制，请与我们联系。

请求演示：

```json
curl https://api.openai.com/v1/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F purpose="fine-tune" \
  -F file="@mydata.jsonl"
```

响应：

```json
{
  "id": "file-XjGxS3KTG0uNmNOK362iJua3",
  "object": "file",
  "bytes": 140,
  "created_at": 1613779121,
  "filename": "mydata.jsonl",
  "purpose": "fine-tune"
}
```

#### Request body(入参详解)

> - `file` （string，必填）
>
>   要上传的 [JSON Lines](https://link.juejin.cn?target=https%3A%2F%2Fjsonlines.readthedocs.io%2Fen%2Flatest%2F) 文件名。
>
>   如果 `purpose` 设置为 **“fine-tune”**，则每行都是一个JSON记录，其中包含“prompt”和“completion”字段，表示您的 [training examples(训练示例)](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fguides%2Ffine-tuning%2Fprepare-training-data)。
>
> - `purpose` （string，必填）
>
>   上传文档的预期用途。
>
>   使用 **“fine-tune”** 进行 [Fine-tuning(微调)](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Ffine-tunes)。这样可以验证上传文件的格式。

### 1.8. [Fine-tunes](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Ffine-tunes) 微调

管理微调作业以将模型定制为您的特定训练数据。

相关指南：[Fine-tune models(微调模型)](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fguides%2Ffine-tuning)

####  [Create fine-tune](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Ffine-tunes%2Fcreate)

```json
POST
https://api.openai.com/v1/fine-tunes
```

创建一个工作，从给定的数据集中微调指定模型。

响应包括已入队的作业的详细信息，包括 作业状态 和 完成后微调模型的名称。

[了解有关微调的更多信息](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fguides%2Ffine-tuning)。

请求演示：

```json
curl https://api.openai.com/v1/fine-tunes \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "training_file": "file-XGinujblHPwGLSztz8cPS8XY"
  }'
```

响应：

```json
{
  "id": "ft-AF1WoRqd3aJAHsqc9NY7iL8F",
  "object": "fine-tune",
  "model": "curie",
  "created_at": 1614807352,
  "events": [
    {
      "object": "fine-tune-event",
      "created_at": 1614807352,
      "level": "info",
      "message": "Job enqueued. Waiting for jobs ahead to complete. Queue number: 0."
    }
  ],
  "fine_tuned_model": null,
  "hyperparams": {
    "batch_size": 4,
    "learning_rate_multiplier": 0.1,
    "n_epochs": 4,
    "prompt_loss_weight": 0.1,
  },
  "organization_id": "org-...",
  "result_files": [],
  "status": "pending",
  "validation_files": [],
  "training_files": [
    {
      "id": "file-XGinujblHPwGLSztz8cPS8XY",
      "object": "file",
      "bytes": 1547276,
      "created_at": 1610062281,
      "filename": "my-data-train.jsonl",
      "purpose": "fine-tune-train"
    }
  ],
  "updated_at": 1614807352,
}
```

#### Request body(入参详解)

> - `training_file` （string，必填）
>
>   包含 **训练数据** 的已上传文件的ID。
>
>   请参阅 [upload file](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fapi-reference%2Ffiles%2Fupload) 以了解如何上传文件。
>
>   您的数据集必须格式化为 **JSONL文件**，其中每个训练示例都是一个带有 “prompt” 和 “completion” keys 的 JSON对象。此外，您必须上传带有 `fine-tune` 目的的文件。
>
>   有关更多详细信息，请参阅 [微调指南](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fguides%2Ffine-tuning%2Fcreating-training-data)。
>
> - `validation_file` （string，选填）
>
>   包含 **验证数据** 的已上传文件的ID。
>
>   如果您提供此文件，则数据将在微调期间定期用于生成验证指标。这些指标可以在 [微调结果文件](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fguides%2Ffine-tuning%2Fanalyzing-your-fine-tuned-model) 中查看。您的训练和验证数据应该是互斥的。
>
>   您的数据集必须格式化为 **JSONL文件**，其中每个验证示例都是一个带有 “prompt” 和 “completion” keys 的 JSON对象。此外，您必须上传带有 `fine-tune` 目的的文件。
>
>   有关更多详细信息，请参阅 [微调指南](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fguides%2Ffine-tuning%2Fcreating-training-data)。
>
> - `model` （string，选填，Defaults to curie）
>
>   要微调的基础模型名称。
>
>   您可以选择其中之一："ada"、"babbage"、"curie"、"davinci"，或 2022年4月21日 后创建的经过微调的模型。要了解这些模型的更多信息，请参阅 [Models](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fmodels) 文档。
>
> - `n_epochs` （integer，选填，Defaults to 4）
>
>   训练模型的时期数。一个 epoch 指的是完整地遍历一次训练数据集
>
> - `batch_size` （integer，选填，Defaults to null）
>
>   用于训练的批次大小。批次大小是用于训练单个前向和后向传递的训练示例数量。
>
>   默认情况下，批量大小将动态配置为训练集示例数量的约 0.2％，上限为256。
>
>   通常，我们发现较大的批量大小对于更大的数据集效果更好。
>
> - `learning_rate_multiplier` （number，选填，Defaults to null）
>
>   用于训练的学习率倍增器。微调学习率 是预训练时使用的 原始学习率 乘以 此值 得到的。
>
>   默认情况下，学习率的倍增器为 0.05、0.1 或 0.2，具体取决于最终 `batch_size`（较大的批量大小通常使用较大的学习率效果更好）。我们建议尝试在 0.02 到 0.2 范围内实验不同值以找出产生最佳结果的值。
>
> - `prompt_loss_weight` （number，选填，Defaults to 0.01）
>
>   用于提示 tokens 损失的权重。这控制了模型尝试学习生成提示的程度（与始终具有 1.0 权重的完成相比），并且可以在完成很短时为训练添加稳定效果。
>
>   如果提示非常长（相对于完成而言），那么减少此权重可能是有意义的，以避免过度优先考虑学习提示。
>
> - `compute_classification_metrics` （boolean，选填，Defaults to false）
>
>   如果设置了，我们会在每个 epoch 结束时使用验证集计算特定于分类的指标，例如准确率和 F-1 分数。这些指标可以在 [结果文件](https://link.juejin.cn?target=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fguides%2Ffine-tuning%2Fanalyzing-your-fine-tuned-model) 中查看。
>
>   为了计算分类指标，您必须提供一个`validation_file(验证文件)`。此外，对于多类分类，您必须指定 `classification_n_classes`；对于二元分类，则需要指定 `classification_positive_class`。
>
> - `classification_n_classes` （integer，选填，Defaults to null）
>
>   分类任务中的类别数量。
>
>   这个参数在多分类任务中是必需的。
>
> - `classification_positive_class` （string，选填，Defaults to null）
>
>   二元分类中的正类。
>
>   在进行二元分类时，需要此参数来生成精确度、召回率和 F1 指标。
>
> - `classification_betas` （array，选填，Defaults to null）
>
>   如果提供了这个参数，我们会在指定的 beta 值上计算 F-beta分数。F-beta分数 是 F-1分数 的一般化。这仅用于二元分类。
>
>   当 beta 为1时（即F-1分数），精确度和召回率被赋予相同的权重。较大的 beta 值更加注重召回率而不是精确度。较小的 beta 值更加注重精确度而不是召回率。
>
> - `suffix` （string，选填，Defaults to null）
>
>   一个长度最多为 40个字符 的字符串，将被添加到您的 微调模型名称 中。
>
>   例如，`suffix`  为 “custom-model-name” 会生成一个模型名称，如 `ada:ft-your-org:custom-model-name-2022-02-15-04-21-04`。



