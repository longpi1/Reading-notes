# Golang Map源码分析（二、基础操作之写入、扩容）

> 注意当前go版本代码为1.23

```go
// A header for a Go map.
type hmap struct {
        // Note: the format of the hmap is also encoded in cmd/compile/internal/reflectdata/reflect.go.
        // Make sure this stays in sync with the compiler's definition.

        // count: map 中实际存储的键值对数量。
        // 必须是 hmap 结构体的第一个字段，因为内置函数 len() 会直接读取该字段。
        count int

        // flags: 用于存储 map 的状态标志，例如是否正在进行迭代、是否正在进行等量扩容等。
        flags uint8

        // B: buckets 数组大小的以 2 为底的对数。
        // 例如，B=5 表示 buckets 数组的大小为 2^5 = 32。
        // map 最多可以存储 loadFactor * 2^B 个键值对，loadFactor 是负载因子，默认为 6.5。
        B uint8

        // noverflow: 溢出桶的大致数量。
        // 这是一个近似值，因为在并发访问 map 时，noverflow 的更新可能会有延迟。
        // 详细的更新机制可以参考 incrnoverflow 函数的实现。
        noverflow uint16

        // hash0: 哈希种子，用于随机化键的哈希值。
        // 在创建 map 时，会生成一个随机的 hash0 值，用于防止哈希碰撞攻击。
        hash0 uint32


        // buckets: 指向 buckets 数组的指针。 buckets 数组的大小为 2^B。
        // 如果 count 为 0，则 buckets 可能为 nil。
        // 每个 bucket 存储多个键值对，具体数量由 bucketCnt 常量决定，通常为 8。
        buckets unsafe.Pointer

        // oldbuckets: 指向旧 buckets 数组的指针。
        // 仅在 map 扩容时使用。旧 buckets 数组的大小是新 buckets 数组的一半。
        // 在渐进式扩容过程中，键值对会逐渐从 oldbuckets 迁移到 buckets。
        oldbuckets unsafe.Pointer

        // nevacuate: 渐进式扩容的进度计数器。
        // 表示已经完成迁移的 buckets 数量。
        // buckets 数组中索引小于 nevacuate 的 bucket 都已经迁移到了新的 buckets 数组。
        nevacuate uintptr


        // extra: 指向 mapextra 结构体的指针，其中包含溢出桶和其他一些字段。
        // 如果没有溢出桶，则 extra 可能为 nil。
    	// extra.overflow：保存溢出桶链表
		// extra.oldoverflow：保存旧溢出桶链表
		// extra.nextOverflow：下一个空闲溢出桶地址
        extra *mapextra
}
```

上一篇文章我们介绍了go map初始化、，接下来我们看看map的基础操作是如何实现的吧

## 基础操作

### 写入

通过汇编语言可以看到，向 map 中插入或者修改 key，最终调用的是 `mapassign` 函数。

实际上插入或修改 key 的语法是一样的，只不过前者操作的 key 在 map 中不存在，而后者操作的 key 存在 map 中。

mapassign 有一个系列的函数，根据 key 类型的不同，编译器会将其优化为相应的“快速函数”。

| key 类型 | 插入                                                         |
| -------- | ------------------------------------------------------------ |
| uint32   | mapassign_fast32(t *maptype, h *hmap, key uint32) unsafe.Pointer |
| uint64   | mapassign_fast64(t *maptype, h *hmap, key uint64) unsafe.Pointer |
| string   | mapassign_faststr(t *maptype, h *hmap, ky string) unsafe.Pointer |

我们只用研究最一般的赋值函数 `mapassign`。

整体流程与读取比较相似，可以将其分成几个部分依次分析，首先是函数会根据传入的键拿到对应的哈希和桶：

```go
// mapassign 函数是 Go 语言运行时中用于在 map 中赋值的关键函数。它处理了 map 的插入和更新操作，包括哈希计算、桶查找、冲突解决、扩容等重要步骤。
func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer {
        // t: map 的类型信息，包含键和值的类型等。
        // h: 指向 hmap 结构的指针，hmap 是 map 的运行时表示。
        // key: 指向要赋值的键的指针。

        // 返回值：指向与键关联的值的指针。

        // .........前置检查
        
        // 计算键的哈希值
        hash := t.Hasher(key, uintptr(h.hash0))

       // 在计算哈希后设置写入标志，如果哈希计算过程中发生panic，不会错误地标记为写入
        h.flags ^= hashWriting

        // 如果桶数组为 nil，则初始化桶数组
        if h.buckets == nil {
                // 分配一个新的桶数组，初始容量为 1。
                h.buckets = newobject(t.Bucket) // newarray(t.Bucket, 1)
        }

again:
        // 计算键对应的 bucket
        bucket := hash & bucketMask(h.B)
        // 如果哈希表正在扩展，执行扩展操作
        if h.growing() {
                growWork(t, h, bucket)
        }
        // 获取 bucket 的指针
        b := (*bmap)(add(h.buckets, bucket*uintptr(t.BucketSize)))
        // 计算键哈希值的高 8 位（tophash）
        top := tophash(hash)


        // 初始化插入位置相关的变量,（inserti）指向 key 的 hash 值在 tophash 数组所处的位置，另一个(insertk)指向 cell 的位置（也就是 key 最终放置的地址）
        var inserti *uint8        // 指向要插入 tophash 的位置的指针
        var insertk unsafe.Pointer // 指向要插入键的位置的指针
        var elem unsafe.Pointer    // 指向要插入值的位置的指针

bucketloop:
        // 遍历桶中的槽位
        for {
                for i := uintptr(0); i < abi.OldMapBucketCount; i++ {
                        // 如果当前位置的 tophash 不匹配
                        if b.tophash[i] != top {
                                if isEmpty(b.tophash[i]) && inserti == nil {
                                        // 找到一个空位，准备插入
                                        inserti = &b.tophash[i]
                                        insertk = add(unsafe.Pointer(b), dataOffset+i*uintptr(t.KeySize))
                                        elem = add(unsafe.Pointer(b), dataOffset+abi.OldMapBucketCount*uintptr(t.KeySize)+i*uintptr(t.ValueSize))
                                }
                                if b.tophash[i] == emptyRest {
                                        break bucketloop  // 已经到bucket的末尾或下一个bucket
                                }
                                continue
                        }
                        // 匹配 tophash，检查键是否真正匹配
                        k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.KeySize))
                        if t.IndirectKey() {
                                k = *((*unsafe.Pointer)(k))
                        }
                        if !t.Key.Equal(key, k) {
                                continue
                        }
                        // 找到键，更新值
                        if t.NeedKeyUpdate() {
                                // runtime.typedmemmove 将键移动到对应的内存空间中并返回键对应值的地址 val
                                typedmemmove(t.Key, k, key)
                        }
                        elem = add(unsafe.Pointer(b), dataOffset+abi.OldMapBucketCount*uintptr(t.KeySize)+i*uintptr(t.ValueSize))
                        goto done
                }
                // 如果当前bucket已满，移动到overflow bucket
                ovf := b.overflow(t)
                if ovf == nil {
                        break
                }
                b = ovf
        }

        // 如果没有找到键，需要插入新键值对
        // 如果需要增长表，或溢出桶过多，开始增长
        if !h.growing() && (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) {
                hashGrow(t, h)
                goto again  // 表增长后，数据位置可能改变，重新尝试
        }

        if inserti == nil {
                // 如果所有bucket都满了，创建新的overflow bucket
                newb := h.newoverflow(t, b)
                inserti = &newb.tophash[0]
                insertk = add(unsafe.Pointer(newb), dataOffset)
                elem = add(insertk, abi.OldMapBucketCount*uintptr(t.KeySize))
        }

        // 在找到的位置存储新的键和元素
        if t.IndirectKey() {
                kmem := newobject(t.Key)
                *(*unsafe.Pointer)(insertk) = kmem
                insertk = kmem
        }
        if t.IndirectElem() {
                vmem := newobject(t.Elem)
                *(*unsafe.Pointer)(elem) = vmem
        }
        // runtime.typedmemmove 将键移动到对应的内存空间中并返回键对应值的地址 val
        typedmemmove(t.Key, insertk, key)
        *inserti = top
        h.count++

done:
        // 确保写入标志在操作结束时被正确清除
        if h.flags&hashWriting == 0 {
                fatal("concurrent map writes")
        }
        h.flags &^= hashWriting
        if t.IndirectElem() {
                elem = *((*unsafe.Pointer)(elem))
        }
        return elem
}
```

主要步骤总结：**0.前置检查 -> 1.计算哈希值 ->2. 定位桶 -> 3.遍历桶内条目 -> 4.1在桶中查找键，比较 tophash 和 key ，若找到则更新（更新后直接跳转步骤5），否则准备插入-> 4.2.插入新键值对，更新相关数据结构->5. 清除写入标志并返回值的指针**

重点介绍一下步骤4.1与4.2：

**4.1在桶中查找键**

- 遍历目标桶中的槽位，比较每个槽位的 `tophash`（哈希值的高8位）与目标 `tophash`。
- 如果 `tophash` 不匹配，且槽位为空，记录该位置作为潜在的插入点。
- 如果槽位为 `emptyRest`，表示已经到达桶的末尾，停止遍历。
- 如果 tophash匹配，进一步比较键是否相同：
  - 若键相同，执行更新操作，将新值写入对应位置，然后跳转到完成步骤。
- 如果当前桶遍历完仍未找到匹配的键，继续遍历溢出桶（overflow bucket）。

**4.2.插入新键值对，更新相关数据结构**

- 如果在桶中没有找到匹配的键，则准备插入新键值对。

- 在插入之前，检查是否需要对哈希表进行扩容：
  - 如果插入新键后负载因子超过阈值，或者溢出桶过多，触发哈希表的扩容操作（`hashGrow`），然后重新尝试插入操作。
- 如果找到了空位，直接使用该位置。如果没有空位，创建一个新的溢出桶。

- 将新键和值插入到找到的空位中：
  - 如果键或值是间接类型（`IndirectKey` 或 `IndirectElem`），则需要先分配内存。
- 更新 `tophash`，增加计数器 `count`，表示成功插入了一个新键值对。

> 需注意，哈希并不会在 runtime.mapassign这个运行时函数中将值拷贝到桶中，该函数只会返回内存地址，真正的赋值操作是在编译期间插入的：
>
> ```go
> 00018 (+5) CALL runtime.mapassign_fast64(SB)
> 00020 (5) MOVQ 24(SP), DI               ;; DI = &value
> 00026 (5) LEAQ go.string."88"(SB), AX   ;; AX = &"88"
> 00027 (5) MOVQ AX, (DI)                 ;; *DI = AX
> ```
>
> 其中 `24(SP)` 是该函数返回的值地址，我们通过 `LEAQ` 指令将字符串的地址存储到寄存器 `AX` 中，`MOVQ` 指令将字符串 `"88"` 存储到了目标地址上完成了这次哈希的写入。

### 扩容

上面介绍写入过程时因为篇幅我们省略了扩容操作，随着哈希表中元素的逐渐增加，哈希的性能会逐渐恶化，所以我们需要通过扩容更多的桶和更大的内存保证哈希的读写性能：

Go 语言采用一个 bucket 里装载 8 个 key，定位到某个 bucket 后，还需要再定位到具体的 key，这实际上又用了时间换空间。

当然，这样做，要有一个度，不然所有的 key 都落在了同一个 bucket 里，直接退化成了链表，各种操作的效率直接降为 O(n)，是不行的。

因此，需要有一个指标来衡量前面描述的情况，就是`装载因子`。

mapassign函数会在以下两种情况发生时触发哈希的扩容：

1. 装载因子超过阈值，源码里定义的阈值是 6.5。
2. 使用了太多溢出桶；overflow 的 bucket 数量过多：当 B 小于 15，也就是 bucket 总数 2^B 小于 2^15 时，如果 overflow 的 bucket 数量超过 2^B；当 B >= 15，也就是 bucket 总数 2^B 大于等于 2^15，如果 overflow 的 bucket 数量超过 2^15。

对应扩容条件的源码如下：

```go
func overLoadFactor(count int, B uint8) bool {
	//abi.OldMapBucketCount: 这是一个为了兼容旧版本 Go 实现的常量。在较旧的版本中，map 的实现方式略有不同。这个常量确保了在新版本中，即使 count 很小，也能保持与旧版本的行为一致。
	//loadFactorNum 和 loadFactorDen: 这两个常量共同定义了 map 的目标负载因子。通过调整这两个常量的值，可以控制 map 的空间利用率和查找效率之间的平衡。 在 Go 1.18 及以后版本中, loadFactorNum/loadFactorDen 的值约为 6.5。
	//简而言之，overLoadFactor 函数的作用是：根据预期的元素数量 (count) 和桶的数量 (2 的 B 次方)，判断 map 的负载因子是否会超过预设值。如果超过，则返回 true，表示需要增加桶的数量 (增加 B 的值) 以降低负载因子。
    return count > abi.OldMapBucketCount && uintptr(count) > loadFactorNum*(bucketShift(B)/loadFactorDen)
}

// tooManyOverflowBuckets reports whether noverflow buckets is too many for a map with 1<<B buckets.
// Note that most of these overflow buckets must be in sparse use;
// if use was dense, then we'd have already triggered regular map growth.
func tooManyOverflowBuckets(noverflow uint16, B uint8) bool {
    // If the threshold is too low, we do extraneous work.
    // If the threshold is too high, maps that grow and shrink can hold on to lots of unused memory.
    // "too many" means (approximately) as many overflow buckets as regular buckets.
    // See incrnoverflow for more details.
    if B > 15 {
       B = 15
    }
    // The compiler doesn't see here that B < 16; mask B to generate shorter shift code.
    return noverflow >= uint16(1)<<(B&15)
}
```

第 1 点：每个 bucket 有 8 个空位，在没有溢出，且所有的桶都装满了的情况下，装载因子算出来的结果是 8。因此当装载因子超过 6.5 时，表明很多 bucket 都快要装满了，查找效率和插入效率都变低了。在这个时候进行扩容是有必要的。

第 2 点：是对第 1 点的补充。就是说在装载因子比较小的情况下，这时候 map 的查找和插入效率也很低，而第 1 点识别不出来这种情况。表面现象就是计算装载因子的分子比较小，即 map 里元素总数少，但是 bucket 数量多（真实分配的 bucket 数量多，包括大量的 overflow bucket）。

对于命中条件 1，2 的限制，都会发生扩容。但是扩容的策略并不相同，毕竟两种条件应对的场景不同。

对于条件 1，元素太多，而 bucket 数量太少，很简单：将 B 加 1，bucket 最大数量（2^B）直接变成原来 bucket 数量的 2 倍。于是，就有新老 bucket 了。注意，这时候元素都在老 bucket 里，还没迁移到新的 bucket 来。而且，新 bucket 只是最大数量变为原来最大数量（2^B）的 2 倍（2^B * 2）。

对于条件 2，其实元素没那么多，但是 overflow bucket 数特别多，说明很多 bucket 都没装满。解决办法就是开辟一个新 bucket 空间，将老 bucket 中的元素移动到新 bucket，使得同一个 bucket 中的 key 排列地更紧密。这样，原来，在 overflow bucket 中的 key 可以移动到 bucket 中来。结果是节省空间，提高 bucket 利用率，map 的查找和插入效率自然就会提升。

对于条件 2 的解决方案，曹大的博客里还提出了一个极端的情况：如果插入 map 的 key 哈希都一样，就会落到同一个 bucket 里，超过 8 个就会产生 overflow bucket，结果也会造成 overflow bucket 数过多。移动元素其实解决不了问题，因为这时整个哈希表已经退化成了一个链表，操作效率变成了 `O(n)`。



扩容的入口[`runtime.hashGrow`](https://draveness.me/golang/tree/runtime.hashGrow)：

```go
//  src/runtime/hashGrow
func hashGrow(t *maptype, h *hmap) {
        // 当 map 中的元素数量超过负载因子时，需要进行扩容。
        // 扩容有两种方式：
        // 1. 桶数量翻倍 (bigger = 1)，用于元素数量显著增加的情况。
        // 2. 桶数量不变，整理溢出桶 (bigger = 0)，用于溢出桶过多的情况，减少溢出桶的数量，提高效率。

        // bigger 变量用于标记是否需要增加桶的数量。默认为 1，表示需要翻倍。B+1 相当于是原来 2 倍的空间
        bigger := uint8(1)

        //对应条件 2 ,查当前元素数量加一（假设即将插入一个新元素）是否超过负载因子,果没有超过负载因子，则选择整理溢出桶的方式，即不增加桶的数量。
        if !overLoadFactor(h.count+1, h.B) {
            	// 进行等量的内存扩容，所以bigger0=0, 变
                bigger = 0
                // 设置 sameSizeGrow 标志，表示这次扩容是整理溢出桶，桶数量不变。
                h.flags |= sameSizeGrow
        }

        // 保存旧的桶数组。将老 buckets 挂到 oldbuckets 上
        oldbuckets := h.buckets

        // 创建新的桶数组。
        // makeBucketArray 函数会根据新的桶数量 (h.B + bigger) 创建一个新的桶数组，并返回指向新桶数组的指针以及指向预创建的溢出桶的指针。
        newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil)

        // 清除迭代器相关的标志位，并保留 oldIterator 标志。
        // 如果当前有迭代器正在使用 map，则设置 oldIterator 标志，
        // 这样在后续的 evacuate 操作中可以正确处理迭代器。
        flags := h.flags &^ (iterator | oldIterator)
        if h.flags&iterator != 0 {
                flags |= oldIterator
        }

        // 提交扩容操作（原子操作，对垃圾回收器可见）。
        // 更新桶的数量。
        h.B += bigger
        // 更新标志位。
        h.flags = flags
        // 将旧的桶数组保存到 oldbuckets 中，用于后续的 evacuate 操作。
        h.oldbuckets = oldbuckets
        // 将新的桶数组设置为当前桶数组。
        h.buckets = newbuckets
        // 初始化 nevacuate 计数器，表示还没有迁移任何桶。
        h.nevacuate = 0
        // 初始化 noverflow 计数器，表示新的桶数组中还没有溢出桶。
        h.noverflow = 0

        // 如果存在溢出桶相关的信息，则处理溢出桶。
        if h.extra != nil && h.extra.overflow != nil {
                // 检查 oldoverflow 是否已经存在，如果存在则说明之前的扩容操作还没有完成，抛出异常。
                if h.extra.oldoverflow != nil {
                        throw("oldoverflow is not nil")
                }
                // 将当前的溢出桶列表移动到 oldoverflow 中，并将 overflow 置为空。
                // 这样在后续的 evacuate 操作中可以将旧的溢出桶中的元素迁移到新的桶数组中。
                h.extra.oldoverflow = h.extra.overflow
                h.extra.overflow = nil
        }

        // 如果预创建了溢出桶，则将其保存到 mapextra 结构中。
        if nextOverflow != nil {
                // 如果 mapextra 结构不存在，则创建一个新的。
                if h.extra == nil {
                        h.extra = new(mapextra)
                }
                // 将预创建的溢出桶保存到 nextOverflow 中。
                h.extra.nextOverflow = nextOverflow
        }

        // 哈希表数据的实际拷贝操作由 growWork() 和 evacuate() 函数增量完成。
        // growWork() 函数负责调度 evacuate() 函数，evacuate() 函数负责将旧桶中的元素迁移到新的桶数组中。
        // 这种增量拷贝的方式可以避免一次性拷贝大量数据导致的性能问题，
        // 并保证在扩容过程中 map 的正常使用。
}
```

哈希在扩容的过程中会通过 [`runtime.makeBucketArray`](https://draveness.me/golang/tree/runtime.makeBucketArray) 创建一组新桶和预创建的溢出桶，随后将原有的桶数组设置到 `oldbuckets` 上并将新的空桶设置到 `buckets` 上，溢出桶也使用了相同的逻辑更新，下图展示了触发扩容后的哈希,引自[Go 语言设计与实现](https://draveness.me/golang)：

![hashmap-hashgrow](https://img.draveness.me/2020-10-18-16030322432573/hashmap-hashgrow.png)



我们在 [`runtime.hashGrow`](https://draveness.me/golang/tree/runtime.hashGrow) 中还看不出来等量扩容和翻倍扩容的太多区别，等量扩容创建的新桶数量只是和旧桶一样，该函数中只是创建了新的桶，并没有对数据进行拷贝和转移。哈希表的数据迁移的过程在是 [`runtime.evacuate`](https://draveness.me/golang/tree/runtime.evacuate) 中完成的，它会对传入桶中的元素进行再分配。

```go
func evacuate(t *maptype, h *hmap, oldbucket uintptr) {
	b := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize)))
	newbit := h.noldbuckets()
	if !evacuated(b) {
		var xy [2]evacDst
		x := &xy[0]
		x.b = (*bmap)(add(h.buckets, oldbucket*uintptr(t.bucketsize)))
		x.k = add(unsafe.Pointer(x.b), dataOffset)
		x.v = add(x.k, bucketCnt*uintptr(t.keysize))

		y := &xy[1]
		y.b = (*bmap)(add(h.buckets, (oldbucket+newbit)*uintptr(t.bucketsize)))
		y.k = add(unsafe.Pointer(y.b), dataOffset)
		y.v = add(y.k, bucketCnt*uintptr(t.keysize))
```

[`runtime.evacuate`](https://draveness.me/golang/tree/runtime.evacuate) 会将一个旧桶中的数据分流到两个新桶，所以它会创建两个用于保存分配上下文的 [`runtime.evacDst`](https://draveness.me/golang/tree/runtime.evacDst) 结构体，这两个结构体分别指向了一个新桶：

![hashmap-evacuate-destination](https://img.draveness.me/2020-10-18-16030322432579/hashmap-evacuate-destination.png)



## 问题



## 参考链接

1.[Go 程序员面试笔试宝典](https://golang.design/go-questions)

2.《Go学习笔记》

3.[Go 语言设计与实现](