# go中sync.map介绍

### 一、`sync.Map` 是如何实现线程安全的？—— 核心思想：“读写分离” 与 “空间换时间”

`sync.Map` 的实现非常精妙，它不像“用一个大 `Mutex` 锁住整个 `map`”那么简单粗暴。那种方式会导致所有操作（读和写）都互相阻塞，性能极差。

`sync.Map` 的核心设计思想是**“读写分离”**和**“空间换时间”**，通过两个内部 map 来实现高效的并发访问。

#### 1. 核心数据结构

`sync.Map` 内部主要包含两个 map：

- **`read` (readOnly)**：
  - 这是一个**只读**的 `map`（实际上是 `atomic.Value` 类型，里面存着一个 `readOnly` 结构体）。
  - 因为它是只读的，所以对它的**并发读取完全不需要加锁**！这是 `sync.Map` 高性能读取的关键。
  - 它包含了 map 中的绝大部分数据。
- **`dirty` (map[interface{}]\*entry)**：
  - 这是一个**可读可写**的 `map`，**必须加锁（`sync.Mutex`）才能访问**。
  - 它只存储那些**新写入或被修改**的数据。可以把它看作是 `read` map 的一个“增量”或“脏数据”缓冲区。
  - `dirty` 中包含了 `read` map 的所有数据，以及新写入的数据。

#### 2. 操作流程解析

我们来看一下 `Load` (读), `Store` (写), `Delete` (删) 这三个核心操作是如何在这两个 map 上协同工作的。

- **`Load(key)` (读操作)**：

  1. **优先读 `read` map**：首先，不加锁，直接原子地读取 `read` map。
  2. 如果**在 `read` map 中找到了 `key`**，并且这个 `key` 对应的 `entry` 没有被标记为“已删除”，那么直接返回结果。**这是最快、最常见的路径，完全无锁。**
  3. **如果 `read` map 中没找到**，说明这个 `key` 可能是新写入的，或者是一个不存在的 `key`。此时，**必须加锁**去访问 `dirty` map。
  4. 在 `dirty` map 中查找 `key`。如果找到，就返回结果；如果还是没找到，说明这个 `key` 确实不存在，返回 `nil`。

- **`Store(key, value)` (写操作)**：

  1. 优先写 `dirty` map

     ：

     - 首先，不加锁，尝试在 `read` map 中查找。如果找到了，就尝试**原子地（CAS）**更新这个 `key` 对应的 `entry` 的值。如果更新成功，操作就结束了。这是一种针对“**覆盖更新已存在的热点 key**”的优化。

  2. 如果 `read` map 中没找到，或者 CAS 更新失败，就**必须加锁**，操作 `dirty` map。

  3. 在 `dirty` map 中找到/创建对应的 `entry`，并更新其值。

  4. **`dirty` map 的“提升”**：当 `dirty` map 中积累了一定数量的、`read` map 中没有的新数据后（这个过程称为 `misses` 计数），`sync.Map` 会执行一个关键操作：将**整个 `dirty` map 的内容“提升”为新的 `read` map**，并清空 `dirty` map。这样，后续对这些新数据的读取又可以走快速的无锁路径了。

- **`Delete(key)` (删除操作)**：

  1. 删除操作比较特殊，它不是真正的物理删除。
  2. 它会首先在 `read` map 中找到 `key` 对应的 `entry`，并将其**原子地标记为“已删除”**。
  3. 然后，它会像 `Store` 操作一样，加锁去 `dirty` map 中也记录这个删除操作。
  4. 真正的物理删除，要等到后续 `dirty` map 提升为 `read` map 时才会发生。

#### 3. “空间换时间”的体现

`sync.Map` 同时维护了 `read` 和 `dirty` 两个 map，其中 `dirty` 包含了 `read` 的全量数据，这显然是**用额外的内存空间（空间）**，换取了**绝大多数读操作的无锁性能（时间）**。

------

### 二、`sync.Map` 适用于什么场景？

理解了它的实现原理，我们就能清晰地知道它的适用场景。`sync.Map` 并非是万能的，它是一种**特化的并发 `map`**，专门为以下**特定场景**设计：

**核心适用场景**：**读多写少**的并发场景，特别是当**写入的 key 往往是新的 key**时。

1. **缓存 (Cache)**：
   - 一个 key 一旦被写入，后续会被**大量地读取**，而很少被修改或删除。例如，缓存数据库查询结果、全局配置项等。这是 `sync.Map` **最典型、最理想**的应用场景。
   - 读操作几乎都是无锁的，性能极高。写操作虽然有锁，但因为是“写少”场景，所以锁竞争不激烈。
2. **一次写入，多次读取的元数据 (Write-Once, Read-Many)**：
   - 在一个系统的初始化阶段，将一些配置或元数据写入 `sync.Map`。
   - 在系统运行期间，这些数据会被成千上万的 Goroutine 并发地读取，而不再进行修改。

**为什么不适用于“写多”或“读写均衡”的场景？**

- 如果写操作非常频繁，会导致 `dirty` map 的锁**竞争非常激烈**。
- 每次写操作都可能需要加锁，这会使其性能**退化**，甚至**不如**一个简单的“**用 `sync.RWMutex` 保护的普通 `map`**”。
- 频繁的写操作还会导致 `dirty` map 频繁地被提升为 `read` map，这个提升过程本身也是有开销的。

------

### 三、与 `map + sync.RWMutex` 的对比

| 特性         | `sync.Map`                                                   | `map + sync.RWMutex` (读写锁保护的普通 map)                  |
| :----------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| **实现原理** | **读写分离**，`read` (无锁) + `dirty` (有锁)                 | **共享锁**，所有读操作共享一把读锁，所有写操作获取一把排他的写锁。 |
| **性能**     | **读操作极快**（在命中 `read` map 时，无锁，可扩展性好）。<br>**写操作较慢**（需要加锁，可能有提升开销）。 | **读操作需要加读锁**（虽然多个读可以并行，但仍有锁的开销）。<br>**写操作需要加写锁**，会阻塞所有读和写。 |
| **适用场景** | **读多写少**的场景，特别是缓存。                             | **通用场景**，包括读写均衡、写多读少的场景。逻辑更简单直观。 |
| **易用性**   | 内置，开箱即用。                                             | 需要自己封装一个结构体来管理 map 和 RWMutex。                |
| **内存**     | 占用更多内存（两个 map）。                                   | 占用内存较少。                                               |

### 总结

- `sync.Map` 通过**读写分离**的精妙设计，为**“读多写少”**的并发场景提供了极致的读取性能。
- 它的核心优势在于**绝大多数读操作是完全无锁的**，这在高并发读取时避免了锁竞争带来的性能瓶壁。
- 它**不是**一个可以替代 `map + RWMutex` 的“万金油”。在写操作频繁或读写均衡的场景下，使用传统的读写锁方案可能性能更好、逻辑也更简单。

**如何选择？**

- 当你能明确你的场景是**一次写入、多次读取**，或者**读操作的频率远大于写操作**时（例如，实现一个缓存），`sync.Map` 是一个绝佳的选择。
- 对于其他更通用的、读写模式不确定的并发场景，从一个**被 `sync.RWMutex` 保护的普通 `map``** 开始，通常是更安全、更直观的选择。